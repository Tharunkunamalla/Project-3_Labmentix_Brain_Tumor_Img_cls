{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atoJvrkfkSup"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers,models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrJ26ZcSlOIF",
        "outputId": "010b1fb7-1f16-4461-c998-6c10b6a3ea96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "train_path = '/content/drive/MyDrive/Datasets/train'\n",
        "test_path = '/content/drive/MyDrive/Datasets/test'\n",
        "valid_path = '/content/drive/MyDrive/Datasets/valid'"
      ],
      "metadata": {
        "id": "CEGTkzS48aks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image size and batch\n",
        "IMG_SIZE = (224, 224) #Height, width in pixels\n",
        "BATCH_SIZE = 32 #Number of images to be processed..."
      ],
      "metadata": {
        "id": "0cKqbybL8soU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generators for train\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "#Data generators for valid\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "lThecd_l8vku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generators for test\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "q2Cv1H1a8xqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train data needs variety (augment), Test data needs clarity (just rescale)\n",
        "<br>\n",
        "These tricks help your model see different versions of the same image — this is called Data Augmentation. It makes the model stronger and better at generalizing.\n",
        "\n",
        "For test data, we don’t use flips or rotations — we just rescale. Test data should be clean."
      ],
      "metadata": {
        "id": "6Ok2vbXrnne6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_gen = valid_datagen.flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxO4dWC18zcq",
        "outputId": "1439f5f5-43a6-4463-dff3-42877fefa4f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1695 images belonging to 4 classes.\n",
            "Found 246 images belonging to 4 classes.\n",
            "Found 512 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNetV2: A famous model trained on millions of images (ImageNet) — it already knows useful patterns like edges, textures, etc."
      ],
      "metadata": {
        "id": "xsDo9dl7f97n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer Learning Model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze base model\n",
        "\n",
        "#model\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(), #Reduces data from base model into a flat feature vector.\n",
        "    layers.Dense(128, activation='relu'), #Fully connected layer — learns complex patterns.\n",
        "    layers.Dropout(0.3), #Turns off 30% neurons randomly during training to avoid overfitting.\n",
        "    layers.Dense(train_gen.num_classes, activation='softmax')#Final layer — gives class probabilities.\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "g-8kPFdS81_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam optimizer (a fast learner)\n",
        "The loss function — categorical_crossentropy for multi-class classification."
      ],
      "metadata": {
        "id": "vl7fzkFNgZ8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6Y0bp6V84r4",
        "outputId": "ec634ddb-7f1b-484b-d56d-87155a06441d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8919 - loss: 0.2995"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 4s/step - accuracy: 0.8918 - loss: 0.2997 - val_accuracy: 0.8398 - val_loss: 0.4570\n",
            "Epoch 2/10\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.8856 - loss: 0.3130 - val_accuracy: 0.8359 - val_loss: 0.4668\n",
            "Epoch 3/10\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.8856 - loss: 0.3058 - val_accuracy: 0.8652 - val_loss: 0.3866\n",
            "Epoch 4/10\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.9104 - loss: 0.2236 - val_accuracy: 0.8828 - val_loss: 0.3398\n",
            "Epoch 5/10\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3s/step - accuracy: 0.9114 - loss: 0.2227 - val_accuracy: 0.8633 - val_loss: 0.4086\n",
            "Epoch 6/10\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.9280 - loss: 0.1968 - val_accuracy: 0.8477 - val_loss: 0.4310\n",
            "Epoch 7/10\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.9309 - loss: 0.1991 - val_accuracy: 0.8438 - val_loss: 0.4667\n",
            "Epoch 8/10\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3s/step - accuracy: 0.9436 - loss: 0.1598 - val_accuracy: 0.8613 - val_loss: 0.4034\n",
            "Epoch 9/10\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.9196 - loss: 0.1910 - val_accuracy: 0.8555 - val_loss: 0.4308\n",
            "Epoch 10/10\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.9476 - loss: 0.1401 - val_accuracy: 0.8027 - val_loss: 0.6061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model.save('best_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg3LFTQ3868K",
        "outputId": "0a77454d-8d67-4290-9775-ab5e621e61cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save class names\n",
        "with open('class_names.txt', 'w') as f:\n",
        "    f.write('\\n'.join(list(train_gen.class_indices.keys())))  #Saves the list of class names (like ['glioma', 'meningioma', 'pituitary']) to a text file.\n",
        "    #Later when the model gives output like [0, 0, 1], you can convert it back to label name using this file."
      ],
      "metadata": {
        "id": "GrsB_HyhD2mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "84r719cVJWRw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}